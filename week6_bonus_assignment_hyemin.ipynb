{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안녕하세요 투빅스 보충 과제입니다 :)\n",
    "\n",
    "안녕하세요 투빅스 12기 김태한입니다 :)\n",
    "\n",
    "이번 과제는 코로나 바이러스로 예상치 못한 휴식시간이 생겨 여러분의 딥러닝 감을 유지하고자 드리게 되었습니다.  \n",
    "\n",
    "투빅이분들이라면 분명 쉽게 해낼거라 믿습니다!!\n",
    "\n",
    "\n",
    "모르시는 거 있으시면 저 그리고 12기 멘토분들을 많이 많이 괴롭혀주세요!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분들은 저번 과제로 뉴럴넷 구현을 이미 한번 하셨습니다!  \n",
    "\n",
    "사실 이번 과제의 최종 목적도 뉴럴넷 구현인데요 이미 한번 하셨고 실력들이 워낙 출중하셔서 금방금방 하실수 있으실거에요.  \n",
    "\n",
    "구현에 바로 들어가기에 앞서 전체 네트워크 구조와 각 구성요소의 행렬 차원 및 오차역전파(back propagation) 복습이 1번 과제입니다.  \n",
    "\n",
    "**?** 에 들어갈 수식을 채워주시면 됩니다!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Shape 정리\n",
    "\n",
    "n : sample_data 수  \n",
    "d : input_dimension  \n",
    "h : hidden_layer_dimension  \n",
    "c : output_dimension  \n",
    "\n",
    "X : input_data  \n",
    "W1 : layer1_weight  \n",
    "b1 : layer1_bias  \n",
    "H : X*W1+b1\n",
    "A : activation function 거친 value\n",
    "W2 : layer2_weight  \n",
    "b2 : layer2_bias  \n",
    "S : A*W2+b2  \n",
    "P : softmax 거친 value  \n",
    "\n",
    "X==(n,d)  \n",
    "W1==(d,h)  \n",
    "b1==(h,)  \n",
    "H==(b1,A) \n",
    "A==(n,h)  \n",
    "W2==(h,c)  \n",
    "b2==(c,) \n",
    "S==(b2,W2) \n",
    "P==(n,c)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix 미분 정리\n",
    "$H = XW+b　　　(n,h) = (n,d)x(d,h)+(h,)$  \n",
    "$L = f(H)$  \n",
    "$\\frac{\\partial L}{\\partial W} = \\frac{\\partial H}{\\partial W} \\times \\frac{\\partial L}{\\partial H} = X\\frac{\\partial L}{\\partial H}$ 　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial X} = \\frac{\\partial H}{\\partial W} \\times \\frac{\\partial L}{\\partial H} = \\frac{\\partial L}{\\partial H}{\\ W}$ 　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial b} = 1*\\frac{\\partial L}{\\partial H}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Layers Chain Rule 정리\n",
    "**Forward** \n",
    "\n",
    "$H = XW_{1} + b$  \n",
    "$A = ReLU(H)$  \n",
    "$S = AW_{2} + b_{2}$  \n",
    "$P = Softmax(S)$  \n",
    "$L = -LogLikelihood(P)$\n",
    "\n",
    "\n",
    "**Backward**\n",
    "\n",
    "$\\frac{\\partial L}{\\partial S} = P-T$　:　T는 Label  \n",
    "$\\frac{\\partial L}{\\partial W_{2}} = \\frac{\\partial S}{\\partial W_{2}}\\frac{\\partial L}{\\partial S} = A  $ 　  \n",
    "$\\frac{\\partial L}{\\partial b_{2}} = 1*\\frac{\\partial L}{\\partial S} = P-T$  \n",
    "$\\frac{\\partial L}{\\partial A} = \\frac{\\partial L}{\\partial S}\\frac{\\partial S}{\\partial A} = X$　\n",
    "$\\frac{\\partial L}{\\partial H} = \\frac{\\partial A}{\\partial H}\\frac{\\partial L}{\\partial A}$  \n",
    "$\\frac{\\partial L}{\\partial W_{1}} = \\frac{\\partial H}{\\partial W_{1}}\\frac{\\partial L}{\\partial H} = X^{T}\\frac{\\partial L}{\\partial H}$  \n",
    "$\\frac{\\partial L}{\\partial b_{1}} = \\frac{\\partial L}{\\partial H}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같이 드린 파일중 model.py라는 파일이 있을거에요!!!  \n",
    "그 친구의 빈칸을 채워주시면 되겠습니다~!!  \n",
    "model.py의 함수는 assignment3의 모델 만들기에서 사용되니 참고하시면서 채워주시면 도움이 될거에요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class TwoLayerNet():\n",
    "    \"\"\"\n",
    "    2 Layer Network를 만드려고 합니다.\n",
    "\n",
    "    해당 네트워크는 아래의 구조를 따릅니다.\n",
    "\n",
    "    input - Linear - ReLU - Linear - Softmax\n",
    "\n",
    "    Softmax 결과는 입력 N개의 데이터에 대해 개별 클래스에 대한 확률입니다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, input_size, hidden_size, output_size, std=1e-4):\n",
    "         \"\"\"\n",
    "         네트워크에 필요한 가중치들을 initialization합니다.\n",
    "         initialized by random values\n",
    "         해당 가중치들은 self.params 라는 Dictionary에 담아둡니다.\n",
    "         \n",
    "         Inputs:\n",
    "         -input_size: input 데이터의 변수 개수 -> D\n",
    "         -hidden_size: 히든 층의 H 개수 -> H\n",
    "         -output_size: 클래스 개수 -> C\n",
    "\n",
    "         \"\"\"\n",
    "\n",
    "         self.params = {}\n",
    "         self.params[\"W1\"] = std * np.random.randn(input_size, hidden_size)\n",
    "         self.params[\"b1\"] = np.random.randn(hidden_size)\n",
    "         self.params[\"W2\"] = std * np.random.randn(hidden_size, output_size)\n",
    "         self.params[\"b2\"] = np.random.randn(output_size)\n",
    "\n",
    "    def forward(self, X, y=None):\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        Inputs:\n",
    "        - X: input 데이터 (N, D), 각각의 X[i]는 training 샘플\n",
    "        - y: 훈련 레이블 (N,) 벡터, y[i]는 X[i]의 레이블, 각각의 y[i]는\n",
    "        정수이다.    ㅍ  ㅠ 66 ㅠ\n",
    "\n",
    "        Linear - ReLU - Linear - Softmax - CrossEntropy Loss\n",
    "\n",
    "        y가 주어지지 않으면 Softmax 결과 p와 Activation 결과 a를 return합니다. p와 a 모두 backward에서 미분할때 사용합니다.\n",
    "        y가 주어지면 CrossEntropy Error를 return합니다.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        W1, b1 = self.params[\"W1\"], self.params[\"b1\"]\n",
    "        W2, b2 = self.params[\"W2\"], self.params[\"b2\"]\n",
    "        N, D = X.shape\n",
    "\n",
    "        # 여기에 p를 구하는 작업을 수행하세요.\n",
    "\n",
    "        h = X.dot(W1)+b1\n",
    "        a = np.maximum(0,h)\n",
    "        o = h.dot(W2) + b2\n",
    "        p = np.exp(o)/np.sum(np.exp(o),axis=1).reshape(-1,1)\n",
    "\n",
    "        if y is None:\n",
    "            return p, a\n",
    "        \n",
    "        # 여기에 Loss를 구하는 작업을 수행하세요.\n",
    "        \n",
    "        Loss =  np.sum(-1 * (scores[range(N),y].reshape((N,1))) + np.log(np.sum((np.exp(scores)), axis=1).reshape((N, 1)))) / N\n",
    "        print(\"Loss:{}\".format(Loss))\n",
    "        return Loss\n",
    "\n",
    "\n",
    "\n",
    "    def backward(self, X, y, learning_rate=1e-5):\n",
    "        \"\"\"\n",
    "\n",
    "        X: input 데이터 (N, D)\n",
    "        y: 레이블 (N,)\n",
    "\n",
    "        grads에는 Loss에 대한 W1, b1, W2, b2 미분 값이 기록됩니다.\n",
    "\n",
    "        원래 backw 미분 결과를 return 하지만\n",
    "        여기서는 Gradient Descent방식으로 가중치 갱신까지 합니다.\n",
    "\n",
    "        \"\"\"\n",
    "        W1, b1 = self.params[\"W1\"], self.params[\"b1\"]\n",
    "        W2, b2 = self.params[\"W2\"], self.params[\"b2\"]\n",
    "        N = X.shape[0] # 데이터 개수\n",
    "        grads = {}\n",
    "\n",
    "        p, a = self.forward(X)\n",
    "\n",
    "        # 여기에 파라미터에 대한 미분을 저장하세요.\n",
    "\n",
    "        dp = p\n",
    "        for i in range(p.shape[0]):\n",
    "            for j in range(p.shape[1]):\n",
    "                if(j==y[i]):\n",
    "                    dp[i][j]-=1\n",
    "          # p-y\n",
    "        da = np.heaviside(a,0)\n",
    "\n",
    "        grads[\"W2\"] = np.dot('''?''')\n",
    "        grads[\"b2\"] = np.sum('''?''',axis=0)\n",
    "        grads[\"W1\"] = np.dot('''?''')\n",
    "        grads[\"b1\"] = np.sum('''?''',axis=0)\n",
    "        \n",
    "        #grads[w].reshape(self.params[w].shape)\n",
    "        self.params[\"W2\"] -= learning_rate * grads[\"W2\"]\n",
    "        self.params[\"b2\"] -= learning_rate * grads[\"b2\"]\n",
    "        self.params[\"W1\"] -= learning_rate * grads[\"W1\"]\n",
    "        self.params[\"b1\"] -= learning_rate * grads[\"b1\"]\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "\n",
    "        p, _ = self.forward(X)\n",
    "        \n",
    "        pre_p = np.argmax(p,axis=1)\n",
    "\n",
    "        return np.sum(pre_p==y)/pre_p.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 저희가 구현한 모델을 가지고 한번 cifar-10 dataset을 학습해볼게요!!  \n",
    "근데 시작하기에 앞서 pip install keras 를 해주세요!!  \n",
    "\n",
    "3번과제의 목적은 하이퍼파라미터를 튜닝하던 다른방법을 사용하던 해서 마지막에 그림그리기에서 높은 validation accuracy가 나오도록 하는 과제입니다!!  \n",
    "\n",
    "모델을 2층이아니라 본인만의 3층으로 발전시켜도 좋구요 다른 여러가지 방법들이 있겠죠!?!?!?  \n",
    "\n",
    "가장 높은 validation accuracy를 뽑으신 분께 상품을 드리겠습니다아~!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 load\n",
    "\n",
    "keras 프레임워크를 이용하여 데이터를 로드해 옵니다.  \n",
    "32*32*3차원의 데이터를 3072차원으로 바꾸는 것 까지 해드릴게요.\n",
    "필요하면 sklearn.preprocessing의 scaler를 사용해보셔도 좋습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-3a4043101298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mModel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from Model import TwoLayerNet\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-31c4ea67f2fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cifar10' is not defined"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(x_train, x_test, y_train, y_test):\n",
    "    #change dtype\n",
    "    x_train = np.array(x_train, dtype=np.float64)\n",
    "    x_test = np.array(x_test, dtype=np.float64)\n",
    "    \n",
    "    #reshaping\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], -1))\n",
    "    \n",
    "    y_train = np.reshape(y_train, (y_train.shape[0],))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0],))\n",
    "        \n",
    "    #normalizing\n",
    "    mean_value = np.mean(x_train, axis=0)\n",
    "    x_train -= mean_value\n",
    "    x_test -= mean_value\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-aa7f934ad04f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = preprocessing_data(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-15ab41d68c09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 너무 많아서 5000개랑 1000개만 사용해보도록 할게요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-9d722e2ca7f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = x_train[:5000]\n",
    "y_train = y_train[:5000]\n",
    "x_test = x_test[:1000]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 확인\n",
    "\n",
    "실제 데이터가 어떻게 생겼는지 한번 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-80784060c951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 설정\n",
    "\n",
    "이제 하이퍼파라미터를 설정해볼게요.  \n",
    "hidden_size, epoch_size, batch_size, learning_rate등은 전부 하이퍼 파라미터이니 바꾸면서 도전해보세요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ab6f1022eb1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "epoch_size = 1000\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "N = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 만들기\n",
    "\n",
    "input_size, hidden_size, output_size는 데이터에 맞게 잘 설정해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7420afbb0a1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbatch_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#이번 배치에서 쓸 데이터들 인덱스 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "batch_mask = np.random.choice(N, batch_size) #이번 배치에서 쓸 데이터들 인덱스 추출\n",
    "x_batch = x_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1e97d1f706d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_batch' is not defined"
     ]
    }
   ],
   "source": [
    "nn = TwoLayerNet(x_batch, input_size=input_size, hidden_size=hidden_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-95618922959c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#코드를 보며 epoch, batch에 대해서 이해해봅시다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mbatch_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#이번 배치에서 쓸 데이터들 인덱스 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "history = {'val_acc': [],'val_loss': []} #기록해서 그림 그리자!\n",
    "\n",
    "#코드를 보며 epoch, batch에 대해서 이해해봅시다.\n",
    "for i in range(epoch_size):\n",
    "    for j in range(N//batch_size):\n",
    "        batch_mask = np.random.choice(N, batch_size) #이번 배치에서 쓸 데이터들 인덱스 추출\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = y_train[batch_mask]\n",
    "        \n",
    "        nn.backward(x_batch, t_batch, 1e-7) # 가중치 갱신\n",
    "    \n",
    "    #accuracy와 loss를 기록해둡시다.\n",
    "    history[\"val_acc\"].append(nn.accuracy(x_test, y_test))\n",
    "    history[\"val_loss\"].append(nn.forward(x_test, y_test))\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i, \"test accuracy :\", nn.accuracy(x_test, y_test))\n",
    "        print(i, \"test loss     :\", nn.forward(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그림 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c3cf3a86cbca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0max_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'정확도(%)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'darkred'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#plt.text(3, 14.7, \"<----------------정확도(%)\", verticalalignment='top', horizontalalignment='right')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax_acc = fig.add_subplot(111)\n",
    "\n",
    "ax_acc.plot(range(epoch_size), history['val_acc'], label='정확도(%)', color='darkred')\n",
    "#plt.text(3, 14.7, \"<----------------정확도(%)\", verticalalignment='top', horizontalalignment='right')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Validation Accuracy(%)')\n",
    "ax_acc.grid(linestyle='--', color='lavender')\n",
    "ax_loss = ax_acc.twinx()\n",
    "ax_loss.plot(range(epoch_size), history['val_loss'], label='오차', color='darkblue')\n",
    "#plt.text(3, 2.2, \"<----------------오차\", verticalalignment='top', horizontalalignment='left')\n",
    "plt.ylabel('Validation Error')\n",
    "ax_loss.yaxis.tick_right()\n",
    "ax_loss.grid(linestyle='--', color='lavender')\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()\n",
    "\n",
    "# 나의 최고 validation accuracy는? 두구두구~\n",
    "print(\"나의 최고 validation loss : \",max(history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
